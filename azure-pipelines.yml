# Azure DevOps Pipeline for Terraform Export
# Exports Azure resources using aztfexport and pushes to git repositories

trigger:
  - main
  - master

pr: none

# Schedule: Run weekly on Friday morning at 8:00 AM UTC
schedules:
- cron: "0 8 * * 5"  # Every Friday at 8:00 AM UTC
  displayName: Weekly Terraform Export (Friday Morning)
  branches:
    include:
    - main
    - master
  always: true  # Run even if there are no code changes

parameters:
  - name: subscriptionIds
    displayName: 'Subscription IDs (Optional - comma-separated for manual export, e.g., "sub-id-1,sub-id-2")'
    type: string
    default: ''
  - name: runMode
    displayName: 'Run Mode'
    type: string
    default: 'all'
    values:
      - 'all'      # Export all subscriptions (scheduled/default)
      - 'selected' # Export selected subscriptions (manual - uses subscriptionIds parameter)

variables:
  - group: 'TerraformExport'  # Variable group with configuration
  - name: configPath
    value: 'config/subscriptions.yaml'
  - name: outputDir
    value: '$(Pipeline.Workspace)/exports'
  - name: gitBranch
    value: 'main'
  - name: pushToRepos
    value: 'true'  # Set to 'false' to disable git push

stages:
# Stage 1: Discover and Group Subscriptions (All Mode)
- stage: DiscoverAndGroup
  displayName: 'Discover Subscriptions and Group by SPN'
  condition: eq('${{ parameters.runMode }}', 'all')
  pool:
    vmImage: 'ubuntu-latest'
  jobs:
  - job: DiscoveryJob
    displayName: 'Discover and Group Subscriptions'
    steps:
    - task: GoTool@0
      displayName: 'Install Go (for scripts)'
      inputs:
        version: '1.21.x'

    - task: UsePythonVersion@0
      displayName: 'Setup Python'
      inputs:
        versionSpec: '3.10'
        addToPath: true

    - script: |
        python -m pip install --upgrade pip
        pip install pyyaml
      displayName: 'Install Python dependencies for scripts'

    - task: AzureCLI@2
      displayName: 'Discover Subscriptions with Default SPN'
      inputs:
        azureSubscription: '$(azureServiceConnection)'  # Default SPN
        scriptType: 'bash'
        scriptLocation: 'inlineScript'
        inlineScript: |
          echo "Discovering all subscriptions using default SPN..."
          az account list --query '[].{id:id, name:name, state:state}' -o json > subscriptions.json
          echo "Found subscriptions:"
          cat subscriptions.json | python -m json.tool | head -20
          
          # Parse config to get SPN overrides and group subscriptions
          python scripts/group-subscriptions-by-spn.py \
            --subscriptions subscriptions.json \
            --config $(configPath) \
            --default-spn "$(azureServiceConnection)" \
            --output matrix.json
          
          # Set matrix variable for next stage
          MATRIX_JSON=$(cat matrix.json)
          echo "##vso[task.setvariable variable=exportMatrix;isOutput=true]$MATRIX_JSON"
          echo "Matrix created:"
          cat matrix.json | python -m json.tool
      env:
        azureServiceConnection: $(azureServiceConnection)

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Subscription Groups'
      inputs:
        artifactName: 'subscription-groups'
        path: 'matrix.json'
      condition: always()

# Stage 2: Export All Subscriptions (All Mode)
- stage: Export
  displayName: 'Parallel Terraform Export'
  dependsOn: DiscoverAndGroup
  condition: eq('${{ parameters.runMode }}', 'all')
  pool:
    vmImage: 'ubuntu-latest'
  jobs:
  - job: ExportJob
    strategy:
      matrix: $[ dependencies.DiscoverAndGroup.outputs['DiscoveryJob.exportMatrix'] ]
    template: azure-pipelines/templates/export-job-template.yml
    parameters:
      # CRITICAL: Use default SPN for authentication (compile-time resolution)
      # Matrix variable $(serviceConnection) is for reference/logging only
      # Azure DevOps validates azureSubscription at compile time, not runtime
      serviceConnection: '$(azureServiceConnection)'  # Default SPN (compile-time)
      subscriptionIds: $(subscriptions)  # Matrix variable (runtime)
      outputDir: '$(Pipeline.Workspace)/exports-$(serviceConnection)'
      configPath: '$(configPath)'
      defaultServiceConnection: '$(azureServiceConnection)'

# Stage 3: Export Selected Subscriptions (Selected Mode)
- stage: ExportSelected
  displayName: 'Export Selected Subscriptions'
  condition: and(eq('${{ parameters.runMode }}', 'selected'), ne('${{ parameters.subscriptionIds }}', ''))
  pool:
    vmImage: 'ubuntu-latest'
  jobs:
  - job: PrepareSubscriptionMatrix
    displayName: 'Prepare Subscription Matrix'
    steps:
    - task: GoTool@0
      displayName: 'Install Go (for scripts)'
      inputs:
        version: '1.21.x'

    - task: UsePythonVersion@0
      displayName: 'Setup Python'
      inputs:
        versionSpec: '3.10'
        addToPath: true

    - script: |
        python -m pip install --upgrade pip
        pip install pyyaml
      displayName: 'Install Python dependencies for scripts'

    - task: AzureCLI@2
      displayName: 'Discover Subscriptions and Find SPNs'
      inputs:
        azureSubscription: '$(azureServiceConnection)'  # Use default SPN for discovery
        scriptType: 'bash'
        scriptLocation: 'inlineScript'
        inlineScript: |
          # Parse comma-separated subscription IDs
          SUB_IDS="${{ parameters.subscriptionIds }}"
          IFS=',' read -ra SUB_ARRAY <<< "$SUB_IDS"
          
          # Verify each subscription exists and is accessible
          VALID_SUBS=()
          for SUB_ID in "${SUB_ARRAY[@]}"; do
            SUB_ID=$(echo "$SUB_ID" | xargs)  # Trim whitespace
            if az account show --subscription "$SUB_ID" > /dev/null 2>&1; then
              VALID_SUBS+=("$SUB_ID")
              echo "✓ Subscription $SUB_ID is accessible"
            else
              echo "⚠ Warning: Subscription $SUB_ID not accessible, skipping"
            fi
          done
          
          if [ ${#VALID_SUBS[@]} -eq 0 ]; then
            echo "##[error]No accessible subscriptions found"
            exit 1
          fi
          
          # For each subscription, find its SPN and create matrix entry
          python scripts/prepare-subscription-matrix.py \
            --subscription-ids "$(IFS=','; echo "${VALID_SUBS[*]}")" \
            --config $(configPath) \
            --default-spn "$(azureServiceConnection)" \
            --output matrix.json
          
          # Set matrix variable for next job
          MATRIX_JSON=$(cat matrix.json)
          echo "##vso[task.setvariable variable=exportMatrix;isOutput=true]$MATRIX_JSON"
          echo "Matrix created:"
          cat matrix.json | python -m json.tool
      env:
        azureServiceConnection: $(azureServiceConnection)

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Subscription Matrix'
      inputs:
        artifactName: 'subscription-matrix'
        path: 'matrix.json'
      condition: always()

  - job: ExportJob
    dependsOn: PrepareSubscriptionMatrix
    strategy:
      matrix: $[ dependencies.PrepareSubscriptionMatrix.outputs['exportMatrix'] ]
    template: azure-pipelines/templates/export-job-template.yml
    parameters:
      # CRITICAL: Template parameters must resolve at compile time
      # Cannot use matrix variable $(serviceConnection) here - use default SPN
      # Matrix variable is available at runtime but templates expand at compile time
      serviceConnection: '$(azureServiceConnection)'  # Default SPN (compile-time resolution)
      subscriptionIds: '["$(subscriptionId)"]'  # Matrix variable (runtime, OK for JSON string)
      outputDir: '$(Pipeline.Workspace)/exports-$(subscriptionId)'
      configPath: '$(configPath)'
      defaultServiceConnection: '$(azureServiceConnection)'

# Stage 4: Send Email Report
- stage: SendEmailReport
  displayName: 'Send Backup Email Report'
  dependsOn:
    - Export
    - ExportSelected
  condition: and(always(), ne('${{ parameters.runMode }}', 'selected'))  # Skip for manual selected runs
  pool:
    vmImage: 'windows-latest'  # Windows needed for PowerShell
  jobs:
  - job: EmailReportJob
    displayName: 'Send Email Report'
    steps:
    - task: AzurePowerShell@5
      displayName: 'Send Terraform Backup Email Report'
      inputs:
        azureSubscription: '$(azureServiceConnection)'
        ScriptType: 'FilePath'
        ScriptPath: 'azure-pipelines/backup-monitor/send-backup-report.ps1'
        ScriptArguments: >
          -LogAnalyticsWorkspaceId "$(LOG_ANALYTICS_WORKSPACE_ID)"
          -LogAnalyticsSharedKey "$(LOG_ANALYTICS_SHARED_KEY)"
          -SendGridApiKey "$(SendGridApiKey)"
          -SendGridFrom "$(SendGridFrom)"
          -SendGridTo "$(SendGridTo)"
          -EnvName "$(Environment)"
          -LookbackHours 24
        azurePowerShellVersion: 'LatestVersion'
      continueOnError: true  # Don't fail pipeline if email fails
