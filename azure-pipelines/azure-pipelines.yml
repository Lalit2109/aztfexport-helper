# Azure DevOps Pipeline for Terraform Export
# Exports Azure resources using aztfexport and pushes to git repositories
# Uses matrix strategy for parallel execution by subscription

trigger: none

pr: none

# Two schedules for different subscription sets
schedules:
  - cron: "0 8 * * 1"  # Every Monday at 8:00 AM UTC
    displayName: Schedule 1 - Terraform Export
    branches:
      include:
      - main
      - master
    always: true
    parameters:
      schedule: schedule1

  - cron: "0 8 * * 4"  # Every Thursday at 8:00 AM UTC
    displayName: Schedule 2 - Terraform Export
    branches:
      include:
      - main
      - master
    always: true
    parameters:
      schedule: schedule2

parameters:
  - name: schedule
    displayName: 'Schedule to run'
    type: string
    default: schedule1
    values:
      - schedule1
      - schedule2

variables:
  - group: 'TerraformExport'
  - name: configPath
    value: 'config/subscriptions.yaml'
  - name: outputDir
    value: '$(Pipeline.Workspace)/exports'
  - name: gitBranch
    value: 'main'
  - name: pushToRepos
    value: 'true'

stages:
  - stage: Export
    displayName: 'Terraform Export'
    pool:
      vmImage: 'ubuntu-latest'
    jobs:
      - job: ExportJob
        displayName: 'Export Azure Resources'
        strategy:
          matrix:
            ${{ if eq(parameters.schedule, 'schedule1') }}:
              # Schedule 1 subscriptions
              # To update: Run discovery script and copy the matrix output here
              # python azure-pipelines/scripts/discover-subscriptions.py schedule1
              # Then replace the empty matrix below with the output
              # Example format:
              # sub-123:
              #   subscription_id: 'sub-123'
              #   subscription_name: 'Subscription Name 1'
              # sub-456:
              #   subscription_id: 'sub-456'
              #   subscription_name: 'Subscription Name 2'
            ${{ if eq(parameters.schedule, 'schedule2') }}:
              # Schedule 2 subscriptions
              # To update: Run discovery script and copy the matrix output here
              # python azure-pipelines/scripts/discover-subscriptions.py schedule2
              # Then replace the empty matrix below with the output
              # Example format:
              # sub-789:
              #   subscription_id: 'sub-789'
              #   subscription_name: 'Subscription Name 3'
        steps:
          - task: GoTool@0
            displayName: 'Install Go (for aztfexport)'
            inputs:
              version: '1.21.x'

          - script: |
              echo "Installing aztfexport..."
              go install github.com/Azure/aztfexport@latest
              export PATH=$PATH:$(go env GOPATH)/bin
              aztfexport --version
              echo "##vso[task.prependpath]$(go env GOPATH)/bin"
            displayName: 'Install aztfexport'

          - task: UsePythonVersion@0
            displayName: 'Setup Python'
            inputs:
              versionSpec: '3.10'
              addToPath: true

          - script: |
              python -m pip install --upgrade pip
              pip install -r requirements.txt
            displayName: 'Install Python dependencies'

          - task: TerraformInstaller@0
            displayName: 'Install Terraform'
            inputs:
              terraformVersion: 'latest'

          - script: |
              echo "Cleaning output directory: $(outputDir)"
              if [ -d "$(outputDir)" ]; then
                rm -rf "$(outputDir)"
              fi
              mkdir -p "$(outputDir)"
            displayName: 'Clean export/output directory'

          - task: AzureCLI@2
            displayName: 'Azure Login and Export'
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                echo "Authenticating with Azure..."
                az account set --subscription $(subscription_id)
                az account show
                
                echo "##vso[task.setvariable variable=AZURE_SUBSCRIPTION_ID]$(subscription_id)"
                echo "Logged in to subscription: $(az account show --query name -o tsv)"
                
                git config --global user.name "Azure Pipelines"
                git config --global user.email "azure-pipelines@devops.com"
                
                export PUSH_TO_REPOS=$(pushToRepos)
                export GIT_BRANCH=$(gitBranch)
                export OUTPUT_DIR=$(outputDir)
                export LOG_LEVEL=INFO
                export CONFIG_PATH=$(configPath)
                export SUBSCRIPTION_ID=$(subscription_id)
                export SUBSCRIPTION_NAME=$(subscription_name)
                export AZURE_DEVOPS_PAT=$(System.AccessToken)
                export SYSTEM_ACCESS_TOKEN=$(System.AccessToken)
                export LOG_ANALYTICS_WORKSPACE_ID=$(LOG_ANALYTICS_WORKSPACE_ID)
                export LOG_ANALYTICS_SHARED_KEY=$(LOG_ANALYTICS_SHARED_KEY)
                
                echo "Starting Terraform export for subscription: $(subscription_name)"
                python src/main.py
            env:
              SYSTEM_ACCESS_TOKEN: $(System.AccessToken)
              LOG_ANALYTICS_WORKSPACE_ID: $(LOG_ANALYTICS_WORKSPACE_ID)
              LOG_ANALYTICS_SHARED_KEY: $(LOG_ANALYTICS_SHARED_KEY)

          - script: |
              if [ ! -d "$(outputDir)" ]; then
                echo "Creating output directory: $(outputDir)"
                mkdir -p "$(outputDir)"
              fi
              if [ -z "$(ls -A $(outputDir) 2>/dev/null)" ]; then
                echo "Warning: Output directory is empty, creating placeholder"
                echo "No exports completed" > "$(outputDir)/README.txt"
              fi
              echo "Output directory contents:"
              ls -la "$(outputDir)" || echo "Directory is empty"
            displayName: 'Prepare Output Directory'
            continueOnError: true

          - task: PublishBuildArtifacts@1
            displayName: 'Publish Export Results'
            inputs:
              pathToPublish: '$(outputDir)'
              artifactName: 'terraform-exports-$(subscription_id)'
              publishLocation: 'Container'
            condition: always()

          - script: |
              if [ -f "$(outputDir)/export_results.json" ]; then
                echo "##[section]Export Summary for $(subscription_name)"
                echo '```json'
                cat "$(outputDir)/export_results.json" | python -m json.tool
                echo '```'
              else
                echo "Export results file not found"
              fi
            displayName: 'Generate Summary Report'
            continueOnError: true

  - stage: SendEmailReport
    displayName: 'Send Backup Email Report'
    dependsOn: Export
    condition: always()
    pool:
      vmImage: 'windows-latest'
    jobs:
      - job: EmailReportJob
        displayName: 'Send Email Report'
        steps:
          - task: AzurePowerShell@5
            displayName: 'Send Terraform Backup Email Report'
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              ScriptType: 'FilePath'
              ScriptPath: 'azure-pipelines/scripts/send-backup-report.ps1'
              ScriptArguments: >
                -LogAnalyticsWorkspaceId "$(LOG_ANALYTICS_WORKSPACE_ID)"
                -LogAnalyticsSharedKey "$(LOG_ANALYTICS_SHARED_KEY)"
                -SendGridApiKey "$(SendGridApiKey)"
                -SendGridFrom "$(SendGridFrom)"
                -SendGridTo "$(SendGridTo)"
                -EnvName "$(Environment)"
                -LookbackHours 24
              azurePowerShellVersion: 'LatestVersion'
            continueOnError: true
